\documentclass[modern]{aastex6} 
\setlength{\parskip}{\baselineskip}

%\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[normalem]{ulem}

\newcommand{\transpose}[1]{{#1}^{\!\mathsf T}}
\newcommand{\given}{\,|\,}
\renewcommand{\det}[1]{||{#1}||}
\DeclareMathOperator{\trace}{Tr}

\newcommand{\counts}{C}
\newcommand{\countrate}{\hat{C}}
\newcommand{\exptime}{t_{\mathrm{exp}}}
\newcommand{\model}{\mathcal{M}}
\newcommand{\psf}{\mathcal{P}}
\newcommand{\prf}{\mathcal{R}}
\newcommand{\qe}{Q}
\newcommand{\scene}{\mathcal{S}}
\newcommand{\like}{\mathcal{L}}
\newcommand{\normal}{\mathcal{N}}


\begin{document}
%\title{Image Forward Modeling Techniques}
\author{Image Forward Modeling Techniques}

%\begin{center}
%\today
%\end{center}

\section{Notation}
I try to use script letters for probability distributions (e.g. $\scene$), with parameters as greek letters (e.g. $\gamma$).
Draws from a distribution are denoted by $\sim$.
Functions are given uppercase italic letters (e.g. $\qe$).
Scalar variables are lowercase italic letters.
Vector variables are \sout{bolded} lowercase.
Matrices are \sout{bolded} uppercase.

\section{Introduction}
The goal is to go from the scene to counts in pixels.
The basic function that we are trying to compute (efficiently) is:
\begin{eqnarray}
\countrate_n & = & F_n(\gamma, \beta)
\end{eqnarray}
where $\countrate_n$ is the expected counts in the $n$th pixel,
there are $n=1,2,...N$ pixels,
$\gamma$ are the parameters describing the instrument (PSF, PRF, distortions, etc.),
and ${\bf \beta}$ are the parameters describing the scene (i.e. source positions and shapes).
In the end we will want to calculate
\begin{eqnarray}
\like(\{\counts_n\} \given \{\exptime \, \countrate_n\}) & = & \prod_n \, \frac{e^{-\exptime \, \countrate_n} \, (\exptime \, \countrate_n)^{\counts_n}} {\counts_n !}
\end{eqnarray}
(or probably the Gaussian likelihood since there will be plenty of counts.)
Ideally we will also be able to efficiently calculate (analytically) the gradients of the ln-likelihood with respect to any of the source (and perhaps even instrument) parameters.
Analytic gradients can vastly accelerate both optimization and MCMC bayesian inference.


\section{Full Problem}
What's really happening from a photon's point of view (sort of)?
First it comes from a distribution $\scene(\alpha, \delta [, \nu] \given \beta)$ which we take to be the intensity distribution on the sky, or the \emph{scene},
parameterized by $\beta$.
It then travels through the the atmosphere (if there is one), then the telescope optics, finally reaching the detector plane.
During this travel the photon is diffracted, so that its position is now in iteself a PDF (called the point spread function, $\psf$).
Upon striking the detector the wavefunction is collapsed and the detector position is drawn from this PDF, 
with some probability related to the quantum efficiency of the detector at that position (and the reflectivity of the optics, etc.).
One must also consider gaps in the detector, and intrapixel sensitivity variations, which might be folded into a spatially dependent QE or pixel response function, 
or alternatively combined with the PSF somehow.
The mapping from the celestial position to the detector plane depends on the distortion of the optics and the aforemention probabilistic draw from $\psf$.
This can all be represented by 
\begin{eqnarray}
\label{eqn:photon}
\alpha_j, \delta_j [, \nu_j] & \sim & \scene(\beta)\\
x_j, y_j & = & D(\alpha_j, \delta_j)  \nonumber \\ 
\Delta x_j, \Delta y_j & \sim & \psf(\gamma, x_j, y_j [, \nu_j]) \nonumber \\
\countrate_n & \propto & \lim_{J\to\infty} \frac{1}{J} \sum^J_{j=1} \qe_n(x_j+ \Delta x_j, y_j + \Delta y_j [, \nu_j]) \nonumber
\end{eqnarray}
where $\scene$ is the sky instensity distribution in celestial coordinates 
and depends on parameters $\beta$,
$\alpha_j$ and $\delta_j$ are the coordinates of the $j$th draw from $\scene$,
$D$ is the mapping from celestial to detector coordinates $(x, y)$ including distortion,
$\psf$ is the point-spread-function in detector coordinates and depends on parameters $\gamma$ as well as the detector location,
$\Delta x_j, \Delta y_j$ are draws from $\psf$,
$\qe_n(x, y)$ is the detector quantum efficiency of the $n$th pixel at location $(x, y)$ (usually something close to a bivariate boxcar),
and $\countrate_n$ is the expected countrate in pixel $n$ per unit time and total number of photons due to celestial sources (i.e. excluding detector background.)
The scene can be expressed as a sum of individual source distributions $\scene = \sum_{m=1}^M \scene_m$.
In what follows we will drop $\nu$ from consideration, assuming that $\qe(\nu)$ is a constant that can be factored out.


In the limit of infinite exposure time (or very many photons), we can replace the sum of a large dumber of draws with integrals to obtain the expected count rate.
\begin{eqnarray}
\label{eqn:psf_convolve}
\model(x, y | \gamma, \beta) & = & \iint \, dx' \, dy' \, \psf(x - x', y-y' \given \gamma, x', y') \, \scene( D^{-1}(x', y') \given \beta) \\
\countrate_n & = & \iint_{A_n} \, dx \, dy \, \qe_n(x, y) \, \model(x, y \given \gamma, \beta) \nonumber
\end{eqnarray}
where $A_n$ is the region of the $n$th pixel, 
$\model$ is the PSF-convolved scene,
$\psf$ is the point-spread function (which depends on the input position of the photon),
and $D$ is the mapping from sky coordinates to detector coordinates, including distortions.
One question is whether it makes more sense to think of the pixels as rectangles in detector coordinates and project the scene into these coordinates as we have done above, 
or to project the pixel boundaries (and $\psf$ and $\qe$) into celestial coordinates.
This probably depends on the form of $D$ and on how the $\qe$ and $\psf$ functions are determined.
Nevertheless, by switching the order of integration we can write
\begin{eqnarray}
\label{eqn:prf_integral}
\prf_n(x', y' | \gamma) & = & \iint_{A_n} \, dx \, dy \, \qe_n(x, y) \, \psf(x' - x, y' - y \given \gamma, x, y) \\
\countrate_n & = & \iint \, dx' \, dy' \, \prf_n(x', y' \given \gamma) \, \scene( D^{-1}(x', y') \given \beta) \nonumber
\end{eqnarray}
where $\prf_n(x', y')$ gives the response of a pixel to a point source at detector coordinates $(x', y')$ including the effect of the pixel-averaged PSF.
This form can be easier to compute, since this pixel response function (PRF) can be specified beforehand, or at least once approximated includes the annoying integral over $A_n$.

These convolutions and integrals can be analytically intractable, or time consuming.
This is especially true the case of complicated forms for $\psf$, $\prf$, $\scene$ or the function $D$.
Much of the guts of any forward modeling algorithm will be concerned with approximating this integral,
 especially in a way that yields analytic gradients.


\section{Approximation by Gaussian Mixtures and Subgridding}
One method to make the integrals more tractable is to calculate $\prf$ and $\scene$ on fine grids and calculate \ref{eqn:prf_integral} directly on this grid.
The grid has to be fine enough that the integral can be approximated by a sum; 
  that is, the grid must fully sample the PRF and the scene.
In principle the precision can be dialed up or down by increasing the fineness of the grids.
\begin{eqnarray}
\label{eqn:prf_grid}
\countrate_{n'} & \approx & \sum_{i,j} \prf_{n'}(x_i, y_j \given \gamma) \, \scene( D^{-1}(x_i, y_j) \given \beta) \nonumber
\end{eqnarray}
It can then be rebinned to produce the actual pixel $\countrate_n$.
One approach to obtain gradients with respect to the parameters $\gamma, \beta$ is to further approximate $\prf$ and $\scene$ by mixtures of Gaussians.
This allows one to write the countrate as 
\begin{eqnarray}
\prf_{n'}(x, y \given \gamma)  & = & \sum_k w_k(\gamma) \, \normal(x, y \given \mu_{k, n'}(\gamma), \Sigma_k(\gamma)) \\
\scene(x, y \given \beta) & = & \sum_\ell w_\ell(\beta) \, \normal(D^{-1}(x, y) \given \mu_\ell(\beta), \Sigma_\ell(\beta)) \nonumber \\
\countrate_{n'} & = & \sum_{i,j}\sum_{k} \, w_k \, \normal(x_i, y_j \given \mu_{k, n'}, \Sigma_{k, n'}) \, \sum_\ell w_\ell \, \normal(D^{-1}(x_i, y_j) \given \mu_{\ell}, \Sigma_{\ell}) \nonumber
\end{eqnarray}
where $\normal(a, b \given \mu, \Sigma)$ is the bivariate normal distribution with location $\mu$ and covariance matrix $\Sigma$ evaluated at $(a, b)$.

The drawbacks here are:
   1) evaluating large numbers of exponentials
   2) finding nice representations of parameterized scenes and PRFs in terms of mixtures of Gaussians such that the gradients of the Gaussian parameters with respect to the scene parameters $\beta$ are relatively simple
   3) limited accuracy of the mixture of Gaussians approximation.
   4) Gaussians do not have a defined maximum frequency and are thus always undersampled to some degree by any grid.
   5) Location dependent PSF or PRF can be unwieldy.
One could also replace the $\prf$ mixture of Gaussians with the polynomial or spline approximation discussed below.
I think the Tractor does something like \ref{eqn:psf_convolve} but with a $\delta$-function $\qe$, in which case the PSF and the PRF are equivalent.

\subsection{Method for Approximating Sersic profiles with Gaussians}
Following \citet{hogg_mog}, but we: 
  1) use absolute celestial units (e.g. mas); 
  2) fix the radii of the gaussians (on sky), including one at $r=0$;
  3) apply a small blurring to the Sersic profile and Gaussians before fitting (using analytic Sersic blurring formulae from \citet{trujillo01}); and
  4) Fit for the amplitudes as a function of both $n_{sersic}$ and half-light radius $r_h$.

We do this for two reasons.
First because we don't want to be calculating tons of gaussians below a scale that matters for the PRF.
Second because the fixed radii of the gaussians will allow us to spline the amplitudes as a function of $n_{sersic}$ and $r_h$ for easy derivatives, so that we can fit for $n$.

This all results in a fixed number $M$ of Gaussians for each profile,
with amplitudes $a_m(n, r_h)$, zero mean, and covariances $\Sigma_{m,i,j} = \delta_{i,j} \, r_m^2$ 
where here $\delta_{i,j}$ is the Kroneker-$\delta$ and $r_m$ is the dispersion  of the $m$th  Gaussian (in mas or something like it).
We also re-normalize so that 
\begin{eqnarray}
%\sum_m^M \frac{a_m}{2\,\pi\,\sqrt{\det{\Sigma_m}}} & = & 1
\sum_m^M a_m & = & 1
\end{eqnarray}

\subsection{Astrometric Distortions}
We need to be able to convert between celestial coordinates and on-sky parameters (e.g. the half-light radius in arcseconds, the position angle on the sky) to image or pixel coordinates.
We will make the approximation that for any region of interest the astrometric distortion can  be approximated by an affine transformation.
Indeed this will be part of the definition of a region of interest.

The standard FITS style astrometry for such a situation \citep{greisen02} is something like
\begin{eqnarray}
c & = & T \, (\mu_p - \mu_0) + c_0
\end{eqnarray}
where $c$ are the celestial coordinates ($\alpha$, $\delta$),
$\mu_p$ are the pixel coordinates ($x$, $y$),
$\mu_0$ gives an image or region dependent reference pixel,
$c_0$ are the celestial coordinates of that reference pixel,
and $T$ is the region dependent transformation matrix (often represented in FITS headers by \texttt{CD\_ij} entries).
$T$ need not have a determinant of 1, but it must be non-singular. 

We will define
\begin{eqnarray}
D & = & T^{-1} \\
\mu_p & = & D \, (c - c_0) + \mu_0 \nonumber \\
d & = &\sqrt{\det{D}} \nonumber
\end{eqnarray}
and use the matrix $D$ going forward.
The scalar $d$ is a dilation factor, which would be important if we defined our fixed radii (or rather fixed dispersion) galaxy Gaussians  in the pixel space.
Note that for a given subregion of a particular exposure the matrix $D$ and the reference coordinates $\mu_0$, $c_0$ are fixed.


\subsection{Analytic convolutions and transformations to pixel space}
Assuming that we have represented the galaxy and the PRF as mixtures of Gaussians we can write the convolution of the galaxy with the PRF as
\begin{eqnarray}
I(\mu_p) & = & \sum_{m=1}^M \sum_{\ell=1}^L \psi \, \, a_m \, a_\ell \, \normal(\mu_p \given \mu_m + \mu_\ell, \Sigma'_m + \Sigma_\ell)
\end{eqnarray}
where $\psi$ is the total source flux,
$\mu_p$ is the pixel central coordinates,
the $a$ are the normalized amplitudes of the Gaussian,
$\Sigma'_m$  and $\mu_m$ describes a galaxy Gaussian rotated and stretched into the image plane,
and $\Sigma_\ell$ and $\mu_\ell$ describe a PSF gaussian.
For a single term, we can write more explicitly
\begin{eqnarray}
I_{m, \ell}(\mu_p) & = & \, A  \, \exp(-0.5 \, \transpose{(\mu_p -\mu_{m,\ell})} \, F \, (\mu_p -\mu_{m,\ell})) \\
A & = & \frac{ \psi \, a_m \, a_\ell \, \sqrt{\det{F}}}{2\pi} \\
\Sigma & = & (\Sigma'_m + \Sigma_\ell) \nonumber \\
 F & = & \Sigma^{-1} \nonumber \\
\mu_{m,\ell} & = & \mu_m + \mu_\ell \nonumber \\
\mu_m & = & D\, (c - c_0) + \mu_0 \nonumber \\  
\Sigma'_m & = & D\, R \, S \, \Sigma_m \, \transpose{S} \, \transpose{R} \, \transpose{D}\nonumber 
\end{eqnarray}
where $S$ is the scale matrix parameterized by the (on-sky) axis ratio $q$,
$R$ is the rotation matrix parameterized by the (on-sky) position angle of the major axis $\varphi$, 
$D$ is the distortion matrix to go from on-sky to pixel coordinates,
and $\Sigma_m$ is the covariance matrix describing the $m$th Gaussian in the untransformed (circularly symmetric) on-sky coordinate space.
Note that $\det{R}=\det{S}=1$.
Also $\det{D}$ is constant.

The Gaussian in pixel space has 6 parameters $\phi_g$:
the amplitude $A = (\psi \, a_m \, a_\ell \, \sqrt{\det{F}})/(2\pi)$,
the two parameters of the mean $\mu_{m,\ell} = x_{m, \ell}, y_{m, \ell}$,
and the three parameters of the inverse covariance matrix $F_{xx}$,
$F_{yy}$,
and $F_{xy}=F_{yx}$.

There are 7 on-sky galaxy source parameters $\theta_s$:
the total flux $\psi$,
the celestial coordinates $c= (\alpha, \delta)$,
the Sersic index $n$, 
the half-light radius in  celestial units (e.g. degrees or milliarcseconds) $r_h$,
the axis ratio $q = (b/a)$,
and position angle $\varphi$.
In general we will want to construct the Jacobian between $\phi_g$ and $\theta_s$ for each Gaussian.


Now, one option to deal with the galaxy size parameter is to let the size of each galaxy Gaussian be set by the scale matrix $S$, so that the whole collection of Gaussians grows by replacing the matrix $S$ above with $S'=s\,S$ where $s$ is a scalar size.
In this scheme the amplitudes $a_m$ would be functions only of $n$.
However, the radii of the Gaussians would vary.
However, if for any reason we have made the absolute scale important in our approximation of the Sersic profile by Gaussians (for example by adding a sub-PRF blurring before fitting the profiles, as described above) then this will be problematic and internally inconsistent.
We may also want to use fixed radii for other reasons.
In this case the size of the of the galaxy can come in through the amplitudes only, and the $a_m$ will be functions of both $n$ and $r_h$.


\subsection{Gradients}
We can calculate gradients of the pixel counts with respect to the  image plane Gaussian parameters fairly easily.

We will also need the Jacobian to go from the image plane Gaussian parameters to the galaxy parameters.
%\begin{table}[h!]

\begin{center}
$
\begin{array}{c|ccccccc}
 & \psi & \alpha & \delta & q & \varphi & n & r_h \\
\hline
A      &  \frac{K}{\psi} & -      & -      & \nabla_7 & \nabla_8 &  \frac{K}{a_m}\, \frac{\partial a_m}{\partial n} & \frac{K}{a_m} \,\frac{\partial a_m}{\partial r_h} \\
x      & -         & D_{00} & D_{01} & -        & -        & -               & - \\
y      & -         & D_{10} & D_{11} & -        & -        & -               & - \\
F_{xx} & -         & -      & -      & \nabla_1 & \nabla_4 & -               & - \\
F_{xy} & -         & -      & -      & \nabla_2 & \nabla_5 & -               & - \\
F_{yy} & -         & -      & -      & \nabla_3 & \nabla_6 & -               & - \\
\end{array}
$
\end{center}
%\end{table}

where
\begin{eqnarray}
K & = & \frac{\psi \, a_\ell \, a_m \, \sqrt{\det{F}}}{2\pi} \nonumber \\
\bigl(
  \begin{smallmatrix}
    {\nabla_1} & {\nabla_2} \\
    {\nabla_2} & {\nabla_3}
  \end{smallmatrix}
\bigr)
  & = & \frac{\partial F}{\partial q} \nonumber \\
\bigl(
  \begin{smallmatrix}
    {\nabla_4} & {\nabla_5} \\
    {\nabla_5} & {\nabla_6}
  \end{smallmatrix}
\bigr)
  & = & \frac{\partial F}{\partial \varphi} \nonumber \\
\nabla_7 & = & \frac{ K }{2 \, \det{F}}\frac{\partial\det{F}}{\partial q} \nonumber \\
\nabla_8 & = & \frac{ K }{2 \, \det{F}}\frac{\partial\det{F}}{\partial \varphi} \nonumber \\
\frac{\partial \det{F}}{\partial \theta} & = & \det{F}\, \trace(\Sigma \, \frac{\partial F}{\partial\theta}) \nonumber \\
\frac{\partial F}{\partial \theta} & = & -F\, \frac{\partial \Sigma}{\partial \theta} \, F \nonumber \\
\frac{\partial \Sigma}{\partial q} & = & D\, R\, \frac{\partial S}{\partial q} \, \Sigma_m \, \transpose{S} \, \transpose{R} \, \transpose{D} + D\, R\, S \, \Sigma_m \, \transpose{\frac{\partial S}{\partial q}} \, \transpose{R} \, \transpose{D} \nonumber \\
\frac{\partial \Sigma}{\partial \varphi} & = & D\, \frac{\partial R}{\partial \varphi} \, S\, \Sigma_m \, \transpose{S} \, \transpose{R} \, \transpose{D} +  D\, R\, S \, \Sigma_m \, \transpose{S} \, \transpose{\frac{\partial R}{\partial \varphi}} \, \transpose{D} \nonumber \\
\end{eqnarray}

This is helpful for gradients since the partial derivatives can be written easily as 
 \begin{eqnarray}
\frac{\partial\normal( {\bf c} \given \mu, \Sigma)}{\partial \mu}  & = &  \normal({\bf c} \given \mu, \Sigma) \, \Sigma^{-1} \, ({\bf c}-\mu)\\
\frac{\partial\normal( {\bf c} \given \mu, \Sigma)}{\partial \Sigma}  & = &  \normal({\bf c} \given \mu, \Sigma) \, (\Sigma^{-1} - \Sigma^{-1}\, ({\bf c}-\mu) \, \transpose{({\bf c}-\mu)}\, \Sigma^{-1}) \nonumber
\end{eqnarray}
where we have written the vector ${\bf c} = [a, b]$. 
These expressions can then be chained with e.g. $\partial \Sigma /\partial \beta$, $\partial \mu /\partial \beta$, and $\partial w/\partial \beta$.




\section{Approximation by Polynomials and Sampling}
One way to approximate intractable integrals is through Monte Carlo techniques.
This has the nice property that the precision of the approximation can be dialed up or down by increasing or decreasing the number of samples.
In this scheme we represent each component of the scene as a set of draws from $\scene_m(\alpha, \delta \given \beta_m)$, which we call phonions.
In order to maintain differentiability with respect to the parameters $\beta$, the draws can be fixed in some latent space $\hat{\alpha}, \hat{\delta}$,
possibly with some associated weight $\hat{w}$,
and then transformed to the actual space via affine transformations
\begin{eqnarray}
\hat{\alpha}, \hat{\delta} [, \hat{w}] & \sim & \scene(\beta=\beta_0) \\
\alpha_k, \delta_k & = & F(\hat{\alpha}, \hat{\delta}, \beta) \nonumber \\
w_k & = & G(\hat{w}, \beta) \nonumber \\
x_k, y_k & \sim & D(\alpha_k, \delta_k) \nonumber
\end{eqnarray}
where $F$ is an affine transformation. This has easy derivatives, iff $D$, and $G$ have easy derivatives.

One could then also draw samples from $\psf$ and apply these to the scene samples, following \ref{eqn:photon},
 but this might result in unwanted sampling noise unless the number of samples is very large (which is inefficient).
Furthermore the derivatives of $\qe(x, y)$ with respect to $x$ and $y$ are likely to have discontinuities.
Alternatively, we can use a polynomial approximation to $\prf$ to approximate the integral as
\begin{eqnarray}
\prf_n(x_k, y_k) & \approx & \sum_{i,j} \, R_{n, i, j} \, (x_k - x_n)^i \, (y_k - y_n)^j \\
\countrate_n & \approx & \sum_k \, w_k \, \prf_n(x_k, y_k \given \gamma) \nonumber
\end{eqnarray}
where $x_n, y_n$ are the coordinates of the pixel center or some other suitable reference coordinate for that pixel, 
and the $R_{n,i,j}$ are coefficients to a polynomial approximation of $\prf$.
This has the benefit of making $\prf$ analytically differentiable with respect to $x, y$ (which in turn depend on the parameters $\beta$.
We could also use a mixture of Gaussians approximation for $\prf$ described above, but the polynomial  (or a spline) approximation has some nice properties.


\subsection{Gradients}
How do we do gradients in this scheme?  We want 
\begin{eqnarray}
\frac{\partial\countrate_n}{\partial\beta} & \approx & \sum_k \, \frac{\partial\prf_n(x_k, y_k \given \gamma)}{\partial \beta} \nonumber \\
& \approx & \sum_k\sum_{i,j=0} \, R_{n, i, j} \frac{\partial w_k}{\partial \beta}\, i \, j \, \frac{\partial x_k}{\partial \beta}\, \frac{\partial y_k}{\partial \beta} (x_k - x_n)^{i-1} \, (y_k - y_n)^{j-1}
\end{eqnarray}

\subsection{Draws from the Scene}
There are a frew ways to consider drawing from the scene.
Perhaps the closest to the photon case would be to draw directly from some bivariate flux distribution.
This can be accomplished by calculating the inverse of the bivariate cumulative flux distribution (CFD),
 and then transforming uniform (or regular) sampling in the cumulative flux distribution to $x, y$ or $r, \phi$ pairs.
However, because the flux distributions are usually circularly symmetric in the latent space, we can separate into a CFD as a function of $r$ with a uniform distribution in $\phi$.

Here's what that would look like for a Sersic profile with scale length of 1 (we can change this and the ellipticity through affine transformations) and Sersic index $\eta$.
\begin{eqnarray}
 p(r) & = & \frac{2\pi}{f_{\mbox{total}}} \, r e^{-r^{1/\eta}} \nonumber \\
 p(z)  & = & \frac{2\pi \eta }{f_{\mbox{total}}} \, z^{2\eta - 1} e^{-z} \nonumber \\
f_{\mbox{total}} & = & 2\pi\eta \Gamma(2\eta) \nonumber \\ 
CFD(r) & = & \int_0^r \, p(r') \, dr'  \nonumber \\
   & = & \gamma(2\eta, r^{1/\eta}) / \Gamma(2\eta) \\
\end{eqnarray}
where $\Gamma(n)$ is the gamma function and $\gamma(n, z)$ is the incomplete gamma function.
Transforming uniform or regular draws from the CFD into values for $R$ thus requires the inverse incomplete gamma function.
However, this transformation depends on the value of $\eta$.
Thus everytime a new $\eta$ value is considered, we will need to redo the transformation.
In this case the latent variables are actually the draws from the CFD.
So if we want to vary $\eta$ in the fit then the gradients of this transformation with respect to $\eta$.
Unfortunately there is no way to move between different Sersic indices via only affine transformations of any latent space.
This means we lose the nice quality of keeping all of our transformations simple (i.e. without expensive transcendental functions).

The requirement that we re-transform the CFD draws in draws in $R$ above leads to some additional complexity for derivative calculation, 
since we now need to add another level to the chain rule.
Alternatively, we can associate \emph{weights} to each draw from a fiducial latent CFD.
In this case, instead of re-transforming the CFD draws into $R$ draws, 
we can simply reweight the draws based on the ratio of the desired p(R) to the fiducial p(R) at that $R$.

\subsection{Number of function evaluations and possible caching in each scheme}

\subsection{Levels of parallelization}
There are various places we could parallelize this code, 
some of them more amenable to GPU or MIC parallelization:
\begin{itemize}

\item at the sample level ($k$)

\item at the pixel level ($n$)

\item at the source level ($m$) (this is probably a bad idea, since number of sources may not be well matched to the number of processors, and may be variable.)

\item at the image level
\end{itemize}

\section{Translation into code}
I see two kinds of classes, one for approximation of $\prf$ and one for the $\scene$.
Then one can either draw samples from the scene object or give it a grid on which it will compute the scene (which for a point source will be a single point) and gradients thereof.
Then supply the PRF objects (each image block or maybe even each pixel will have one) with sample points or grid point(s). 
Then either multiply the PRF output by the gridded scene, or sum the output over the scene samples to produce $\countrate_n$


\end{document}